{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fda2088e3ee42fe96652b183b6ce93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Called generate() with API: huggingface\n",
      "********************* Searching for answers to question 0 ********************* \n",
      "==> Selecting a node...\n",
      "==> Expanding node 0...\n",
      "---- Generating one-step thought steps for node 0...\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root directory (one level above rStar) to the path\n",
    "sys.path.append(os.path.abspath(\"..\"))  # assuming this script is run from project root\n",
    "\n",
    "from common.arguments import post_process_args\n",
    "from run_src import do_generate\n",
    "\n",
    "from common.arguments import post_process_args\n",
    "\n",
    "\n",
    "\n",
    "args = Namespace()\n",
    "\n",
    "# ÊâãÂä®ËÆæÁΩÆÊâÄÊúâÂ≠óÊÆµ\n",
    "args.dataset_name = \"GSM8K\"\n",
    "args.model_ckpt = \"Qwen/Qwen2-7B-Instruct\"\n",
    "args.test_json_filename = \"demo_test\"\n",
    "args.api = \"huggingface\"\n",
    "args.num_rollouts = 8\n",
    "args.note = \"notebook_test\"\n",
    "args.data_root = \"../data\"\n",
    "args.prompts_root = \"../prompts\"\n",
    "args.answer_sheets_dir = \"outputs/answer_sheets\"\n",
    "args.run_outputs_dir = \"outputs/run_outputs\"\n",
    "args.run_outputs_root = args.run_outputs_dir\n",
    "args.eval_outputs_root = args.run_outputs_dir\n",
    "args.start_idx = 0\n",
    "args.end_idx = 2\n",
    "args.seed = 42\n",
    "args.model_parallel = False\n",
    "args.tensor_parallel_size = 1\n",
    "args.half_precision = True\n",
    "args.verbose = True\n",
    "args.temperature = 0.8\n",
    "args.top_k = 40\n",
    "args.top_p = 0.95\n",
    "args.max_tokens = 256\n",
    "\n",
    "args.num_subquestions = 1         # Â≠êÈóÆÈ¢òÈááÊ†∑Ê¨°Êï∞ÔºàÁî®‰∫é A1 ÁîüÊàêÔºâ\n",
    "args.num_votes = 2             # ÊØè‰∏™ÈóÆÈ¢òÊäïÁ•®Ê¨°Êï∞ÔºàÁî®‰∫é A2/A3Ôºâ\n",
    "args.max_depth_allowed = 1        # MCTS Ê†ëÊúÄÂ§ßÊ∑±Â∫¶\n",
    "args.num_a1_steps = None          # A1 Ê≠•Êï∞ÔºàNone ‰ª£Ë°®ÈªòËÆ§Ôºâ\n",
    "args.disable_a1 = False           # ÊòØÂê¶Á¶ÅÁî® A1\n",
    "args.disable_a5 = False           # ÊòØÂê¶Á¶ÅÁî® A5\n",
    "args.modify_prompts_for_rephrasing = False\n",
    "args.enable_potential_score = False\n",
    "args.save_tree = False\n",
    "args.mcts_discount_factor = 1.0\n",
    "args.mcts_exploration_weight = 2.0\n",
    "args.mcts_weight_scheduler = \"const\"\n",
    "args.mcts_num_last_votes = None\n",
    "\n",
    "args.decompose_template_path = os.path.join(args.prompts_root, \"GSM8K\", \"decompose\", \"decompose_template.json\")\n",
    "args.decompose_prompt_path = os.path.join(args.prompts_root, \"GSM8K\", \"decompose\", \"decompose_prompt.txt\")\n",
    "args.decompose_prompt_rephrased_path = os.path.join(args.prompts_root, \"GSM8K\", \"decompose\", \"decompose_prompt_rephrased.txt\")\n",
    "\n",
    "args.fewshot_cot_prompt_path = os.path.join(args.prompts_root, \"GSM8K\", \"fewshot_cot\", \"fewshot_cot_prompt.txt\")\n",
    "args.fewshot_cot_config_path = os.path.join(args.prompts_root, \"GSM8K\", \"fewshot_cot\", \"fewshot_cot_config.json\")\n",
    "\n",
    "args.fewshot_ost_prompt_path = os.path.join(args.prompts_root, \"GSM8K\", \"fewshot_ost\", \"fewshot_ost_prompt.txt\")\n",
    "args.fewshot_ost_config_path = os.path.join(args.prompts_root, \"GSM8K\", \"fewshot_ost\", \"fewshot_ost_config.json\")\n",
    "\n",
    "args.rephrasing_prompt_template_path = os.path.join(args.prompts_root, \"GSM8K\", \"rephrasing_prompt_template.txt\")\n",
    "args.fewshot_cot_prompt_rephrased_path = args.fewshot_cot_prompt_path\n",
    "args.fewshot_ost_prompt_rephrased_path = args.fewshot_ost_prompt_path\n",
    "\n",
    "\n",
    "args = post_process_args(args)\n",
    "do_generate.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Valid path: ../prompts/GSM8K/decompose/decompose_template.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"../prompts/GSM8K/decompose/decompose_template.json\"\n",
    "\n",
    "if os.path.exists(path):\n",
    "    print(f\"‚úÖ Valid path: {path}\")\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Current working directory (root path): /home/toz015/delegation_ai_project/rStar/run_src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"üìÅ Current working directory (root path):\", os.getcwd())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
